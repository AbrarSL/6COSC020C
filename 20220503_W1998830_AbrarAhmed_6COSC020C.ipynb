{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "585ba6ba",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b905d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as tnn\n",
    "import torchvision as tvision\n",
    "import torch.optim as toptim\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585575c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a config parameter for automaticaly choosing between CPU/GPU compute depending on whether a NVIDIA CUDA capable GPU is present\n",
    "COMPUTE_DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.device(COMPUTE_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa723b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup dataset parameters and training hyperparameters\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "EVAL_BATCH_SIZE = 1000\n",
    "MEAN = 0.5\n",
    "STD_DEV = 0.5\n",
    "EPOCHS = 20\n",
    "BASE_LEARNING_RATE = 0.001\n",
    "LEARNING_RATE_GAMMA = 0.1\n",
    "LEARNING_RATE_STEP_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9ff7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and std dev from the dataset\n",
    "train_set = tvision.datasets.MNIST(root=\"./trainingdata\", train=True, transform=tvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "flattened_data = torch.stack([img for img, _ in train_set])\n",
    "\n",
    "MEAN = flattened_data.view(1, -1).mean(dim=1).item()\n",
    "STD_DEV = flattened_data.view(1, -1).std(dim=1).item()\n",
    "\n",
    "print(f\"MEAN: {MEAN}\")\n",
    "print(f\"STD_DEV: {STD_DEV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a360b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = tvision.transforms.Compose(\n",
    "    [\n",
    "        tvision.transforms.ToTensor(),\n",
    "        tvision.transforms.RandomRotation(90),\n",
    "        tvision.transforms.Normalize(MEAN, STD_DEV)\n",
    "    ]\n",
    ")\n",
    "\n",
    "eval_transforms = tvision.transforms.Compose(\n",
    "    [\n",
    "        tvision.transforms.ToTensor(),\n",
    "        tvision.transforms.Normalize(MEAN, STD_DEV)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fb90ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "training_set = tvision.datasets.MNIST(root=\"./trainingdata\", train=True, transform=train_transforms, download=True)\n",
    "evaluation_set = tvision.datasets.MNIST(root=\"./evaluationdata\", train=False, transform=eval_transforms, download=True)\n",
    "\n",
    "training_set_loader = torch.utils.data.DataLoader(training_set, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "evaluation_set_loader = torch.utils.data.DataLoader(evaluation_set, batch_size=EVAL_BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509d83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a copy of the data loader so that it can be iterated without affecting the model\n",
    "train_set_imgs, train_set_labels = next(iter(training_set_loader))\n",
    "\n",
    "# Display a few samples\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(20):\n",
    "    img = train_set_imgs[i]\n",
    "    lbl = train_set_labels[i]\n",
    "\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.xlabel(f\"Num: {lbl}\")\n",
    "    plt.imshow(img.numpy().squeeze(), cmap=\"gray\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698fa164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the model layers\n",
    "model = tnn.Sequential(\n",
    "    tnn.Conv2d(1, 32, 3, 1, 1),\n",
    "    tnn.BatchNorm2d(32),\n",
    "    tnn.ReLU(),\n",
    "    tnn.MaxPool2d(2, 2),\n",
    "\n",
    "    tnn.Conv2d(32, 64, 3, 1, 1),\n",
    "    tnn.BatchNorm2d(64),\n",
    "    tnn.ReLU(),\n",
    "    tnn.MaxPool2d(2, 2),\n",
    "\n",
    "    tnn.Flatten(),\n",
    "    tnn.Linear(64 * 7 * 7, 128), # img is 7x7 after going through two 2x2 pooling layers, multiplied then by the number of feature layers\n",
    "    tnn.ReLU(),\n",
    "    tnn.Dropout(0.2),\n",
    "    tnn.Linear(128, 10)\n",
    ").to(COMPUTE_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d2c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimizer, loss and learning rate scheduler functions\n",
    "loss_func = tnn.CrossEntropyLoss()\n",
    "optimizer = toptim.Adam(model.parameters(), lr=BASE_LEARNING_RATE)\n",
    "lr_sched = toptim.lr_scheduler.StepLR(optimizer=optimizer, gamma=LEARNING_RATE_GAMMA, step_size=LEARNING_RATE_STEP_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "425ff618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20\n",
      "Loss: 238.1430402668193/1875\n",
      "Learning Rate: [1.0000000000000007e-13]\n",
      "Epoch: 2/20\n",
      "Loss: 238.17433638544753/1875\n",
      "Learning Rate: [1.0000000000000008e-14]\n",
      "Epoch: 3/20\n",
      "Loss: 241.14338188851252/1875\n",
      "Learning Rate: [1.0000000000000008e-14]\n",
      "Epoch: 4/20\n",
      "Loss: 236.77930071391165/1875\n",
      "Learning Rate: [1.0000000000000009e-15]\n",
      "Epoch: 5/20\n",
      "Loss: 240.48671427322552/1875\n",
      "Learning Rate: [1.0000000000000009e-15]\n",
      "Epoch: 6/20\n",
      "Loss: 241.59788199258037/1875\n",
      "Learning Rate: [1.000000000000001e-16]\n",
      "Epoch: 7/20\n",
      "Loss: 241.5752761955373/1875\n",
      "Learning Rate: [1.000000000000001e-16]\n",
      "Epoch: 8/20\n",
      "Loss: 239.26594388997182/1875\n",
      "Learning Rate: [1.000000000000001e-17]\n",
      "Epoch: 9/20\n",
      "Loss: 236.54134415835142/1875\n",
      "Learning Rate: [1.000000000000001e-17]\n",
      "Epoch: 10/20\n",
      "Loss: 239.55451058829203/1875\n",
      "Learning Rate: [1.000000000000001e-18]\n",
      "Epoch: 11/20\n",
      "Loss: 238.06896029761992/1875\n",
      "Learning Rate: [1.000000000000001e-18]\n",
      "Epoch: 12/20\n",
      "Loss: 240.204026612686/1875\n",
      "Learning Rate: [1.000000000000001e-19]\n",
      "Epoch: 13/20\n",
      "Loss: 239.115065603517/1875\n",
      "Learning Rate: [1.000000000000001e-19]\n",
      "Epoch: 14/20\n",
      "Loss: 237.38285114383325/1875\n",
      "Learning Rate: [1.0000000000000011e-20]\n",
      "Epoch: 15/20\n",
      "Loss: 237.9600958074443/1875\n",
      "Learning Rate: [1.0000000000000011e-20]\n",
      "Epoch: 16/20\n",
      "Loss: 240.63204547856003/1875\n",
      "Learning Rate: [1.0000000000000012e-21]\n",
      "Epoch: 17/20\n",
      "Loss: 235.05793948937207/1875\n",
      "Learning Rate: [1.0000000000000012e-21]\n",
      "Epoch: 18/20\n",
      "Loss: 237.4829010446556/1875\n",
      "Learning Rate: [1.0000000000000012e-22]\n",
      "Epoch: 19/20\n",
      "Loss: 241.77875601453707/1875\n",
      "Learning Rate: [1.0000000000000012e-22]\n",
      "Epoch: 20/20\n",
      "Loss: 239.1194876176305/1875\n",
      "Learning Rate: [1.0000000000000013e-23]\n"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "for epoch in range(EPOCHS):\n",
    "    # Switch to train mode, drops nodes etc\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for img_batch, lbl_batch in training_set_loader:\n",
    "        # Send the data to the GPU if one is available\n",
    "        img_batch = img_batch.to(COMPUTE_DEVICE)\n",
    "        lbl_batch = lbl_batch.to(COMPUTE_DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_outputs = model(img_batch)\n",
    "        batch_loss = loss_func(batch_outputs, lbl_batch)\n",
    "\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += batch_loss.item()\n",
    "\n",
    "    lr_sched.step()\n",
    "    print(f\"Epoch: {epoch + 1}/{EPOCHS}\")\n",
    "    print(f\"Loss: {epoch_loss}/{len(training_set_loader)}\")\n",
    "    print(f\"Learning Rate: {lr_sched.get_last_lr()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c8d2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Accuracy: 97.71%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img_batch, lbl_batch in evaluation_set_loader:\n",
    "        img_batch = img_batch.to(COMPUTE_DEVICE)\n",
    "        lbl_batch = lbl_batch.to(COMPUTE_DEVICE)\n",
    "\n",
    "        batch_outputs = model(img_batch)\n",
    "        prediction_confidence, predicted_class = torch.max(batch_outputs.data, 1)\n",
    "        total_predictions += lbl_batch.size(0)\n",
    "        correct_predictions += (predicted_class == lbl_batch).sum().item()\n",
    "\n",
    "print(f\"\\nFinal Test Accuracy: {100 * correct_predictions / total_predictions:.2f}%\")\n",
    "\n",
    "img_batch, lbl_batch = next(iter(evaluation_set_loader))\n",
    "img_batch, lbl_batch = img_batch.to(COMPUTE_DEVICE), lbl_batch.to(COMPUTE_DEVICE)\n",
    "batch_outputs = model(img_batch)\n",
    "_, preds = torch.max(batch_outputs, 1)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(img_batch[i].cpu().squeeze(), cmap='gray')\n",
    "    plt.title(f\"P: {preds[i].item()} | A: {lbl_batch[i].item()}\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
