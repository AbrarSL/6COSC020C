{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "300571c4",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network Architecture for Character Recognition with the MNIST Dataset\n",
    "\n",
    "## Assessment Details\n",
    "- Student Name: M. I. Abrar Ahmed\n",
    "- Module Code: 6COSC020C - Applied AI\n",
    "- IIT ID: 20220503\n",
    "- UOW ID: W1998830\n",
    "- Coursework Domain: Speech & Text Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087ae3d0",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The ability of the animal brain to percieve, recognize and categorize various symbols can be seen as an incredible biological feat. The speed of the near instant recognition and the robustness of the perceptual powers of the eye-brain pair at this task can served as a benchmark test of artificial intelligence systems. Indeed this task has remained a mainstay for those students starting to dabble in the scientific discipline of machine learning as well as with researchers who have been improving upon this field in a rapid manner throughout the past two decades. This paper will attempt to review the various advancements made within this field within the past two decades, review certain techniques that can be used to varying effect to perform character recognition, implement a robust and accurate Convolutional Neural Network (CNN) model and evaluate the performance of said model using the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7356732",
   "metadata": {},
   "source": [
    "## Application Area Review\n",
    "\n",
    "Character recogition, also known as Optical Character Recognition (OCR), is a cornerstone of the field of computer vision. OCR is a technology with multiple applications, from being an important part of automating older systems such as bank cheques digitization, mail address digitization and license plate identification to being a versatile general purpose tool in the modern day that is efficiently integrated into low power mobile devices. The techniques used for OCR have evolved with time as more and more new research uncovered process optimizations and new methods entirely, for solving the task.\n",
    "\n",
    "For the modern era, that is to say the start of the 21st century, the paper _Gradient-Based Learning Applied to Document Recognition_ by Yann Lecun can be considered to be a major milestone. The paper represents a break from previous techniques that relied heavily on manual feature extraction and sparse, if any, use of machine learning in character recognition tasks. The improved system proposed by the author is underpinned by a reliance on machine learning techniques such as _Gradient-Based Learning_, _Backpropagation_ and the combination of these methods in the construction of a _Convolutional Neural Network_ capable of classifying characters with a high degree of accuracy (Lecun et al., 1998). The automated feature extraction proposed here would prove to be a crucial finding as it would allow other classification techniques to improve their accuracy, in some cases reaching >99% on datasets such as MNIST as demonstrated by (Liu et al., 2003).\n",
    "\n",
    "Although accuracy had already reached levels comparable to humans at this point, these were achieved with complex and less generalized neural network architectures, basic Multi-Layer Perceptrons (MLP) can be described as simple feed-forward neural networks with an input layer, output layer and several hidden layers in-between. Although conceptually simpler and more generalizable, shallow MLPs with few layers cannot come close to the accuracy of complex CNNs (Cireşan et al., 2010). However with the increased availability of GPUs and 'General Purpose Compute' libraries for them, the possibility of training deeper MLPs with a larger number of hidden layers became more feasible. Such 'Deep Learning' techniques were demonstrated to be able to match or exceed the performance of the SOTA CNNs at the time (Cireşan et al., 2010). These results showcased that as massively parallel compute in the form of GPUs continued advance in performance and affordability, the ability to train deeper networks would allow greater accuracy to be achieved in OCR tasks. The ability to train deeper and wider models would be a boon to all types of neural network architectures in general, including CNNs.\n",
    "\n",
    "The next major breakthrough in the machine learning field would be the introduction of the 'Transformer' model architecture. The transformer architecture would solve longstanding issues around the scalability of machine learning models. A transformer architecture avoids the limitations seen in Recurrent Neural Networks, particularly the issue of maintaining context when processing dimensionally complex datapoints. It achieves this by processing data in a parallel sequence and relying on an 'Attention' mechanism to represent the relevance of each point in the sequence to the currently processed point (Vaswani et al., 2017). This architecture was initially intended for Natural Language Processing (NLP) tasks, however the transformer architecture was eventually applied to computer vision tasks as well, with strong results. The 'Vision Transformer' (ViT) model managed to match or exceed the accuracy of SOTA CNN architectures on certain image classification tasks (Dosovitskiy et al., 2020). The ViT model works by 'tokenising' a picture into small 16x16 pixel patches, these patches are then treated analogous to a word-token in an NLP context, this allows the model to 'see' parts of the image all at once (Dosovitskiy et al., 2020). Logically we can see a similarity with this \"Image Patch Token\" and the feature extraction performed by the convolution layers of a CNN. However it must be stressed that although the ViT model outperformed most CNN-based models, it was only able to do when trained on massive datasets consisting of 14 to 300 million images. For smaller datasets, and particularly for very small datasets such as MNIST, CNNs continue to perform the best (Dosovitskiy et al., 2020).\n",
    "\n",
    "In the current landscape CNNs seem to offer the best accuracy with relatively modest datasets such as MNIST or EMNIST, this CNN architecture would incorporate many enhancements found since the initial milestone by Lecun et al. The modern CNN architecture would consist of Convolutional, ReLU Activation, Pooling and Fully Connected layers, the general approach is to increase the number of features extracted by having many convolution layers and repeating a `Convolution->Batch Normalization->ReLU->Pooling` stack for each convolution layer that is added, fully connected layers are kept to a minimum to improve model efficiency and resource usage, as extremely high accuracy can be reached with as little as two or three connected layers (El Ibrahimi et al., 2025). In addition to the model architecture 'Dropout' techniques are used during model training to improve generalization of the model and avoid overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd258791",
   "metadata": {},
   "source": [
    "## Computer Vision Techniques Comparison\n",
    "\n",
    "There are many different potential techniques that can be used for computer vision, here three methods representing fairly different general approaches are taken into consideration, they are,\n",
    "\n",
    "- K-Nearest Neighbour (KNN)\n",
    "- Support Vector Machine (SVM)\n",
    "- Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f5b6ab",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbour\n",
    "\n",
    "KNN relies on calculating the distance between the feature vector of an input and a large number of labelled data points carried within the model. These data points are introduced into the model during the 'training' process, however it must be stressed that this process is unlike what is seen in other ML applications as the model does not attempt to learn any generalized patterns from the data but rather loads the data itself as it's ruleset. When classifying an input value, `K` number of the closest vectors are taken into account, the highest number of repeated classes found within this `K` number of vectors determines the class of the input value. The feature vector for the datapoint is dependent on the specific implementation of KNN, it may be a large dimensional representation of each corresponding pixel value between the input and model data, it may also be a computed, estimate value such as the average value of all pixels in the image. The exact method of extracting the feature vector is important as it can drastically alter the performance of the model.\n",
    "\n",
    "The primary advantage of KNNs are that they essentially require no training iterations as 'training' is really a data load. Conversely KNNs have very undesirable performance characteristics during inference as the distance from the input to each point in the dataset needs to be calculated, this is computationally expensive and scales linearly with the size of the dataset, which restricts the amount of data that can be practically used to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb19086",
   "metadata": {},
   "source": [
    "## Support Vector Machine\n",
    "\n",
    "An SVM classifies data by calculating the position of the feature vector for that data point in a high dimensional space, this position is compared relative to a 'Hyperplane' that is computed during training. The hyperplane is a plane in a lower dimension compared to the feature vector, it divides the two data classes the model was trained on with a margin on either side. During training the positioning of the hyperplane is calculated by finding the vectors that are closest to a class boundary, these are the 'Support Vectors' mentioned. These vectors represent a delineation space between the two classes.\n",
    "\n",
    "Relative to KNN, an SVM is able to provide much faster inference due to not having to calculate the distance between the input feature vector and a full dataset. SVMs also typically use less memory as they can discard the training data points after training and only store the support vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0b5e03",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network\n",
    "\n",
    "CNNs can be considered to be the gold standard for computer vision with small to medium scale datasets. A CNN contains multiple 'Convolution' layers that are used to generate feature maps of the input data. This is achieved by performing multiple convolution operations over the input image with various kernels. These feature maps are able to extract features such as lines, contours, edges and even basic shapes that occur in the input image. These maps are then passed through to one more connected layers that consist of neurons with weights and bias values. The activation of the neurons based on the input value, weight and bias are passed through until it is consolidated into the number of output classes in the final output layer of the network. CNNs are trained on a set of data by repeatedly passing the data through the network, calculating the loss of the model using various algorithms and then tweaking the weights of the model using an algorithm called 'Backpropagation'.\n",
    "\n",
    "As seen previously, CNNs are considered to be the golden standard for character recognition tasks due to their ability to generalize well over a dataset and perform with high accuracy. Due to these reasons the implementation in this paper will be a CNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585ba6ba",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "Given below is the architecture of the implemented neural network.\n",
    "\n",
    "![Model Architecture](./images/AI%20CW.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b905d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as tnn\n",
    "import torchvision as tvision\n",
    "import torch.optim as toptim\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585575c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a config parameter for automaticaly choosing between CPU/GPU compute depending on whether a NVIDIA CUDA capable GPU is present\n",
    "COMPUTE_DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.device(COMPUTE_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa723b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup dataset parameters\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "EVAL_BATCH_SIZE = 1000\n",
    "MEAN = 0.5\n",
    "STD_DEV = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9ff7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and std dev from the dataset\n",
    "train_set = tvision.datasets.MNIST(root=\"./dataset\", train=True, transform=tvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "flattened_data = torch.stack([img for img, _ in train_set])\n",
    "\n",
    "MEAN = flattened_data.view(1, -1).mean(dim=1).item()\n",
    "STD_DEV = flattened_data.view(1, -1).std(dim=1).item()\n",
    "\n",
    "print(f\"MEAN: {MEAN}\")\n",
    "print(f\"STD_DEV: {STD_DEV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fb90ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = tvision.transforms.Compose(\n",
    "    [\n",
    "        tvision.transforms.ToTensor(),\n",
    "        tvision.transforms.RandomRotation(45),\n",
    "        tvision.transforms.RandomAffine(5),\n",
    "        tvision.transforms.Normalize(MEAN, STD_DEV)\n",
    "    ]\n",
    ")\n",
    "\n",
    "eval_transforms = tvision.transforms.Compose(\n",
    "    [\n",
    "        tvision.transforms.ToTensor(),\n",
    "        tvision.transforms.Normalize(MEAN, STD_DEV)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load the dataset\n",
    "training_set = tvision.datasets.MNIST(root=\"./dataset\", train=True, transform=train_transforms, download=True)\n",
    "evaluation_set = tvision.datasets.MNIST(root=\"./dataset\", train=False, transform=eval_transforms, download=True)\n",
    "\n",
    "training_set_loader = torch.utils.data.DataLoader(training_set, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "evaluation_set_loader = torch.utils.data.DataLoader(evaluation_set, batch_size=EVAL_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# label_character_map = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
    "label_character_map = \"0123456789\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509d83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a copy of the data loader so that it can be iterated without affecting the training\n",
    "train_set_imgs, train_set_labels = next(iter(training_set_loader))\n",
    "\n",
    "# Display a single training batch\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(25):\n",
    "    img = train_set_imgs[i]\n",
    "    lbl = train_set_labels[i]\n",
    "\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.xlabel(f\"Num: {label_character_map[lbl]}\")\n",
    "    plt.imshow(img.numpy().squeeze(), cmap=\"gray\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698fa164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the model layers\n",
    "model = tnn.Sequential(\n",
    "    tnn.Conv2d(1, 8, 3, 1, 1),\n",
    "    tnn.BatchNorm2d(8),\n",
    "    tnn.ReLU(),\n",
    "    tnn.MaxPool2d(2, 2),\n",
    "\n",
    "    tnn.Conv2d(8, 16, 3, 1, 1),\n",
    "    tnn.BatchNorm2d(16),\n",
    "    tnn.ReLU(),\n",
    "    tnn.MaxPool2d(2, 2),\n",
    "\n",
    "    tnn.Flatten(),\n",
    "    tnn.Linear(16 * 7 * 7, 128), # img is 7x7 after going through two 2x2 pooling layers, multiplied then by the number of feature layers\n",
    "    tnn.ReLU(),\n",
    "    tnn.Dropout(0.2),\n",
    "    tnn.Linear(128, len(label_character_map)) # The output layer count matches the number of output classes, 10 for full MNIST\n",
    ").to(COMPUTE_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425ff618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "EPOCHS = 10\n",
    "BASE_LEARNING_RATE = 0.0001\n",
    "LEARNING_RATE_GAMMA = 0.1\n",
    "LEARNING_RATE_STEP_SIZE = 2\n",
    "\n",
    "# Setup optimizer, loss and learning rate scheduler functions\n",
    "loss_func = tnn.CrossEntropyLoss()\n",
    "optimizer = toptim.Adam(model.parameters(), lr=BASE_LEARNING_RATE)\n",
    "lr_sched = toptim.lr_scheduler.StepLR(optimizer=optimizer, gamma=LEARNING_RATE_GAMMA, step_size=LEARNING_RATE_STEP_SIZE)\n",
    "\n",
    "# Track the loss during training and evaluation together\n",
    "training_losses = []\n",
    "evaluation_losses = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"=\"*20)\n",
    "    print(f\"Epoch: {epoch + 1}/{EPOCHS}\")\n",
    "\n",
    "    # Ensure node dropout is active by switching to train mode\n",
    "    model.train()\n",
    "\n",
    "    train_correct_predictions = 0\n",
    "    train_total_predictions = 0\n",
    "    train_epoch_loss = 0.0\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        for img_batch, lbl_batch in training_set_loader:\n",
    "            # Send the data to the GPU VRAM if one is available\n",
    "            img_batch = img_batch.to(COMPUTE_DEVICE)\n",
    "            lbl_batch = lbl_batch.to(COMPUTE_DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            batch_outputs = model(img_batch)\n",
    "\n",
    "            batch_loss = loss_func(batch_outputs, lbl_batch)\n",
    "            train_epoch_loss += batch_loss.item()\n",
    "\n",
    "            prediction_confidence, predicted_classes = torch.max(batch_outputs, 1)\n",
    "\n",
    "            train_total_predictions += lbl_batch.size(0)\n",
    "            train_correct_predictions += (predicted_classes == lbl_batch).sum().item()\n",
    "\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        lr_sched.step()\n",
    "        print(f\"Train Model Accuracy: {100 * (train_correct_predictions/train_total_predictions)}\")\n",
    "        print(f\"Train Loss: {train_epoch_loss/len(training_set_loader)}\")\n",
    "        print(f\"Learning Rate: {lr_sched.get_last_lr()}\")\n",
    "\n",
    "    # Ensure model is in evaluation mode to perform inference\n",
    "    # Full network available, no node dropout\n",
    "    model.eval()\n",
    "\n",
    "    eval_correct_predictions = 0\n",
    "    eval_total_predictions = 0\n",
    "    eval_epoch_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img_batch, lbl_batch in evaluation_set_loader:\n",
    "            img_batch = img_batch.to(COMPUTE_DEVICE)\n",
    "            lbl_batch = lbl_batch.to(COMPUTE_DEVICE)\n",
    "\n",
    "            batch_outputs = model(img_batch)\n",
    "\n",
    "            batch_loss = loss_func(batch_outputs, lbl_batch)\n",
    "            eval_epoch_loss += batch_loss.item()\n",
    "\n",
    "            prediction_confidence, predicted_classes = torch.max(batch_outputs.data, 1)\n",
    "\n",
    "            eval_total_predictions += lbl_batch.size(0)\n",
    "            eval_correct_predictions += (predicted_classes == lbl_batch).sum().item()\n",
    "\n",
    "    print(f\"Eval Model Accuracy: {100 * (eval_correct_predictions/eval_total_predictions)}%\")\n",
    "    print(f\"Eval Loss: {eval_epoch_loss/len(evaluation_set_loader)}\")\n",
    "\n",
    "    training_losses.append((train_epoch_loss/len(training_set_loader)))\n",
    "    evaluation_losses.append((eval_epoch_loss/len(evaluation_set_loader)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab5ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    img_batch, lbl_batch = next(iter(evaluation_set_loader))\n",
    "\n",
    "    img_batch = img_batch.to(COMPUTE_DEVICE)\n",
    "    lbl_batch = lbl_batch.to(COMPUTE_DEVICE)\n",
    "\n",
    "    batch_outputs = model(img_batch)\n",
    "    prediction_confidence, predicted_classes = torch.max(batch_outputs, 1)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    for i in range(25):\n",
    "        img = img_batch[i]\n",
    "        lbl = lbl_batch[i]\n",
    "        pred_class = predicted_classes[i]\n",
    "\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        plt.xlabel(f\"P: {label_character_map[pred_class]}, A: {label_character_map[lbl]}, {\"CORRECT\" if pred_class == lbl else \"WRONG\"}\")\n",
    "        plt.imshow(img.cpu().numpy().squeeze(), cmap='gray')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
