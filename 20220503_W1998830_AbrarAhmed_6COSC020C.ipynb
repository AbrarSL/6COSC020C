{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "300571c4",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network Architecture for Character Recognition with the MNIST Dataset\n",
    "\n",
    "## Assessment Details\n",
    "- Student Name: M. I. Abrar Ahmed\n",
    "- Module Code: 6COSC020C - Applied AI\n",
    "- IIT ID: 20220503\n",
    "- UOW ID: W1998830\n",
    "- Coursework Domain: Speech & Text Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087ae3d0",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The ability of the animal brain to percieve, recognize and categorize various symbols can be seen as an incredible biological feat. The speed of the near instant recognition and the robustness of the perceptual powers of the eye-brain pair at this task can served as a benchmark test of artificial intelligence systems. Indeed this task has remained a mainstay for those students starting to dabble in the scientific discipline of machine learning as well as with researchers who have been improving upon this field in a rapid manner throughout the past two decades. This paper will attempt to review the various advancements made within this field within the past two decades, review certain techniques that can be used to varying effect to perform character recognition, implement a robust and accurate Convolutional Neural Network (CNN) model and evaluate the performance of said model using the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7356732",
   "metadata": {},
   "source": [
    "## Application Area Review\n",
    "\n",
    "Character recogition, also known as Optical Character Recognition (OCR), is a cornerstone of the field of computer vision. OCR is a technology with multiple applications, from being an important part of automating older systems such as bank cheques digitization, mail address digitization and license plate identification to being a versatile general purpose tool in the modern day that is efficiently integrated into low power mobile devices. The techniques used for OCR have evolved with time as more and more new research uncovered process optimizations and new methods entirely, for solving the task.\n",
    "\n",
    "For the modern era, that is to say the start of the 21st century, the paper _Gradient-Based Learning Applied to Document Recognition_ by Yann Lecun can be considered to be a major milestone. The paper represents a break from previous techniques that relied heavily on manual feature extraction and sparse, if any, use of machine learning in character recognition tasks. The improved system proposed by the author is underpinned by a reliance on machine learning techniques such as _Gradient-Based Learning_, _Backpropagation_ and the combination of these methods in the construction of a _Convolutional Neural Network_ capable of classifying characters with a high degree of accuracy (Lecun et al., 1998). The automated feature extraction proposed here would prove to be a crucial finding as it would allow other classification techniques to improve their accuracy, in some cases reaching >99% on datasets such as MNIST as demonstrated by (Liu et al., 2003).\n",
    "\n",
    "Although accuracy had already reached levels comparable to humans at this point, these were achieved with complex and less generalized neural network architectures, basic Multi-Layer Perceptrons (MLP) can be described as simple feed-forward neural networks with an input layer, output layer and several hidden layers in-between. Although conceptually simpler and more generalizable, shallow MLPs with few layers cannot come close to the accuracy of complex CNNs (Cireşan et al., 2010). However with the increased availability of GPUs and 'General Purpose Compute' libraries for them, the possibility of training deeper MLPs with a larger number of hidden layers became more feasible. Such 'Deep Learning' techniques were demonstrated to be able to match or exceed the performance of the SOTA CNNs at the time (Cireşan et al., 2010). These results showcased that as massively parallel compute in the form of GPUs continued advance in performance and affordability, the ability to train deeper networks would allow greater accuracy to be achieved in OCR tasks. The ability to train deeper and wider models would be a boon to all types of neural network architectures in general, including CNNs.\n",
    "\n",
    "The next major breakthrough in the machine learning field would be the introduction of the 'Transformer' model architecture. The transformer architecture would solve longstanding issues around the scalability of machine learning models. A transformer architecture avoids the limitations seen in Recurrent Neural Networks, particularly the issue of maintaining context when processing dimensionally complex datapoints. It achieves this by processing data in a parallel sequence and relying on an 'Attention' mechanism to represent the relevance of each point in the sequence to the currently processed point (Vaswani et al., 2017). This architecture was initially intended for Natural Language Processing (NLP) tasks, however the transformer architecture was eventually applied to computer vision tasks as well, with strong results. The 'Vision Transformer' (ViT) model managed to match or exceed the accuracy of SOTA CNN architectures on certain image classification tasks (Dosovitskiy et al., 2020). The ViT model works by 'tokenising' a picture into small 16x16 pixel patches, these patches are then treated analogous to a word-token in an NLP context, this allows the model to 'see' parts of the image all at once (Dosovitskiy et al., 2020). Logically we can see a similarity with this \"Image Patch Token\" and the feature extraction performed by the convolution layers of a CNN. However it must be stressed that although the ViT model outperformed most CNN-based models, it was only able to do when trained on massive datasets consisting of 14 to 300 million images. For smaller datasets, and particularly for very small datasets such as MNIST, CNNs continue to perform the best (Dosovitskiy et al., 2020).\n",
    "\n",
    "In the current landscape CNNs seem to offer the best accuracy with relatively modest datasets such as MNIST or EMNIST, this CNN architecture would incorporate many enhancements found since the initial milestone by Lecun et al. The modern CNN architecture would consist of Convolutional, ReLU Activation, Pooling and Fully Connected layers, the general approach is to increase the number of features extracted by having many convolution layers and repeating a `Convolution->Batch Normalization->ReLU->Pooling` stack for each convolution layer that is added, fully connected layers are kept to a minimum to improve model efficiency and resource usage, as extremely high accuracy can be reached with as little as two or three connected layers (El Ibrahimi et al., 2025). In addition to the model architecture 'Dropout' techniques are used during model training to improve generalization of the model and avoid overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd258791",
   "metadata": {},
   "source": [
    "## Computer Vision Techniques Comparison\n",
    "\n",
    "There are many different potential techniques that can be used for computer vision, here three methods representing fairly different general approaches are taken into consideration, they are,\n",
    "\n",
    "- K-Nearest Neighbour (KNN)\n",
    "- Support Vector Machine (SVM)\n",
    "- Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f5b6ab",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbour\n",
    "\n",
    "KNN relies on calculating the distance between the feature vector of an input and a large number of labelled data points carried within the model. These data points are introduced into the model during the 'training' process, however it must be stressed that this process is unlike what is seen in other ML applications as the model does not attempt to learn any generalized patterns from the data but rather loads the data itself as it's ruleset. When classifying an input value, `K` number of the closest vectors are taken into account, the highest number of repeated classes found within this `K` number of vectors determines the class of the input value. The feature vector for the datapoint is dependent on the specific implementation of KNN, it may be a large dimensional representation of each corresponding pixel value between the input and model data, it may also be a computed, estimate value such as the average value of all pixels in the image. The exact method of extracting the feature vector is important as it can drastically alter the performance of the model.\n",
    "\n",
    "The primary advantage of KNNs are that they essentially require no training iterations as 'training' is really a data load. Conversely KNNs have very undesirable performance characteristics during inference as the distance from the input to each point in the dataset needs to be calculated, this is computationally expensive and scales linearly with the size of the dataset, which restricts the amount of data that can be practically used to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb19086",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "\n",
    "An SVM classifies data by calculating the position of the feature vector for that data point in a high dimensional space, this position is compared relative to a 'Hyperplane' that is computed during training. The hyperplane is a plane in a lower dimension compared to the feature vector, it divides the two data classes the model was trained on with a margin on either side. During training the positioning of the hyperplane is calculated by finding the vectors that are closest to a class boundary, these are the 'Support Vectors' mentioned. These vectors represent a delineation space between the two classes.\n",
    "\n",
    "Relative to KNN, an SVM is able to provide much faster inference due to not having to calculate the distance between the input feature vector and a full dataset. SVMs also typically use less memory as they can discard the training data points after training and only store the support vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0b5e03",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network\n",
    "\n",
    "CNNs can be considered to be the gold standard for computer vision with small to medium scale datasets. A CNN contains multiple 'Convolution' layers that are used to generate feature maps of the input data. This is achieved by performing multiple convolution operations over the input image with various kernels. These feature maps are able to extract features such as lines, contours, edges and even basic shapes that occur in the input image. These maps are then passed through to one more connected layers that consist of neurons with weights and bias values. The activation of the neurons based on the input value, weight and bias are passed through until it is consolidated into the number of output classes in the final output layer of the network. CNNs are trained on a set of data by repeatedly passing the data through the network, calculating the loss of the model using various algorithms and then tweaking the weights of the model using an algorithm called 'Backpropagation'.\n",
    "\n",
    "As seen previously, CNNs are considered to be the golden standard for character recognition tasks due to their ability to generalize well over a dataset and perform with high accuracy. Due to these reasons the implementation in this paper will be a CNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585ba6ba",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "Given below is the architecture of the implemented neural network.\n",
    "\n",
    "\n",
    "![Model Architecture](./images/AI%20CW.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b905d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as tnn\n",
    "import torchvision as tvision\n",
    "import torch.optim as toptim\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585575c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a config parameter for automaticaly choosing between CPU/GPU compute depending on whether a NVIDIA CUDA capable GPU is present\n",
    "COMPUTE_DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.device(COMPUTE_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa723b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup dataset parameters\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "EVAL_BATCH_SIZE = 1000\n",
    "MEAN = 0.5\n",
    "STD_DEV = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c59a6ce",
   "metadata": {},
   "source": [
    "## Dataset and Input\n",
    "\n",
    "The dataset chosen for training and evaluating this model is the MNIST dataset (ylecun/mnist · Datasets at Hugging Face, 2024). This is a popular dataset that is widely used for testing and benchmarking OCR tasks with various techniques. It is a collection of 70,000 labelled images of handwritten digits labelled from 0 to 9. Each image in the MNIST set is sized 28 pixels wide and 28 pixels tall, the strokes for each character are centered within a 20x20 centered area in the image. The images are also in single channel grayscale, which greatly simplifies the amount of processing required for training as well as makes it easier to learn geometric features of the digits.\n",
    "\n",
    "Ultimately the expected input image for the CNN is a 2D tensor with length 28 in each dimension. Access to the dataset is conveniently provided by the `torchvision` module. This does make the integration of this dataset much more convenient and also opens the possibility to switch to another more complex dataset if required, with minimal changes to the rest of the code.\n",
    "\n",
    "### Pre-Processing and Data Augmentation\n",
    "\n",
    "Prior to using the dataset to train the model or perform any inferencing, the dataset it converted from a Python `pillow` image object to a `torch` tensor, this conversion automatically handles another required transformation, that is to normalize each pixel's values between 0 and 1. However for optimal training performance it is also advisable that the mean value and standard deviation of all pixels in an image is also normalized to between 0 and 1. This is achieved with the code snippet given below, where the mean of the whole training dataset is calculated as well as standard deviation, these values are then applied to the actual training dataset as a transformation.\n",
    "\n",
    "In addition to normalizing pixel values, the dataset is also augmented by applying random rotations as well as perspective shifts on each image. This is a technique to avoid the model overfitting to the exact location of strokes in characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9ff7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and std dev from the dataset\n",
    "train_set = tvision.datasets.MNIST(root=\"./dataset\", train=True, transform=tvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "flattened_data = torch.stack([img for img, _ in train_set])\n",
    "\n",
    "MEAN = flattened_data.view(1, -1).mean(dim=1).item()\n",
    "STD_DEV = flattened_data.view(1, -1).std(dim=1).item()\n",
    "\n",
    "print(f\"MEAN: {MEAN}\")\n",
    "print(f\"STD_DEV: {STD_DEV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fb90ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = tvision.transforms.Compose(\n",
    "    [\n",
    "        tvision.transforms.ToTensor(),\n",
    "        tvision.transforms.RandomRotation(15),\n",
    "        tvision.transforms.RandomPerspective(0.1),\n",
    "        tvision.transforms.Normalize(MEAN, STD_DEV)\n",
    "    ]\n",
    ")\n",
    "\n",
    "eval_transforms = tvision.transforms.Compose(\n",
    "    [\n",
    "        tvision.transforms.ToTensor(),\n",
    "        tvision.transforms.Normalize(MEAN, STD_DEV)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load the dataset\n",
    "training_set = tvision.datasets.MNIST(root=\"./dataset\", train=True, transform=train_transforms, download=True)\n",
    "evaluation_set = tvision.datasets.MNIST(root=\"./dataset\", train=False, transform=eval_transforms, download=True)\n",
    "\n",
    "training_set_loader = torch.utils.data.DataLoader(training_set, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
    "evaluation_set_loader = torch.utils.data.DataLoader(evaluation_set, batch_size=EVAL_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# label_character_map = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
    "label_character_map = \"0123456789\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509d83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a copy of the data loader so that it can be iterated without affecting the training\n",
    "train_set_imgs, train_set_labels = next(iter(training_set_loader))\n",
    "\n",
    "# Display a single training batch\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(25):\n",
    "    img = train_set_imgs[i]\n",
    "    lbl = train_set_labels[i]\n",
    "\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.xlabel(f\"Num: {label_character_map[lbl]}\")\n",
    "    plt.imshow(img.numpy().squeeze(), cmap=\"gray\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80f5377",
   "metadata": {},
   "source": [
    "## Model Setup\n",
    "\n",
    "The following codeblock defines the model architecture mapped out in the previous diagram, the architecture of the CNN generally follows the modern best practices in a scaled down manner to further ease the hardware requirements for training and inference. As discussed earlier the CNN follows an architecture whereby one or more convolution layers are stacked with increasing feature layer counts in order to find and extract complex and discriminative features among the dataset. This is passed through a batch normalization layer to reduce the potential of the 'vanishing gradient' issue (El Ibrahimi et al., 2025). The Rectified Linear Unit or ReLU activation function layer introduces non-linearity in the model, allowing it to potentially memorize more complex patterns. Finally there is a 'Fully Connected' layer that is tuned in the course of training to optimize the general digit recognition capability.\n",
    "\n",
    "There is also a call to the `Dropout(0.2)` function seen here, this ensures that during training around 20% of the network's neurons in the fully connected layers are deactivated. This is done to force the neurons to learn generalized patterns instead of overfitting the activation to the training data (Srivastava et al., 2014)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698fa164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the model layers\n",
    "model = tnn.Sequential(\n",
    "    tnn.Conv2d(1, 8, 3, 1, 1),\n",
    "    tnn.BatchNorm2d(8),\n",
    "    tnn.ReLU(),\n",
    "    tnn.MaxPool2d(2, 2),\n",
    "\n",
    "    tnn.Conv2d(8, 16, 3, 1, 1),\n",
    "    tnn.BatchNorm2d(16),\n",
    "    tnn.ReLU(),\n",
    "    tnn.MaxPool2d(2, 2),\n",
    "\n",
    "    tnn.Flatten(),\n",
    "    tnn.Linear(16 * 7 * 7, 128), # img is 7x7 after going through two 2x2 pooling layers, multiplied then by the number of feature layers\n",
    "    tnn.ReLU(),\n",
    "    tnn.Dropout(0.2),\n",
    "    tnn.Linear(128, len(label_character_map)) # The output layer count matches the number of output classes, 10 for full MNIST\n",
    ").to(COMPUTE_DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9235da",
   "metadata": {},
   "source": [
    "The following block initializes the hyperparameters for the model training process as well as performs the training iterations itself. The `EPOCH` variable controls the number of training iterations performed, the `BASE_LEARNING_RATE` defines the value that is used to perform gradient descent during the optimization step. The `LEARNING_RATE_GAMMA` defines the factor of the learning rate for each `LEARNING_RATE_STEP_SIZE` number of epochs elapsed, this allows the model to start off with a higher learning rate at the start of the training iterations when the weights may be far away from a global or local minima in the activation function. This ultimately means that the optimizer is performing large changes at the begining when it is advantageous to do so as a speedup method and then tapering off as we get closer to the minimum, and avoid overshooting the minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425ff618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "EPOCHS = 10\n",
    "BASE_LEARNING_RATE = 0.0001\n",
    "LEARNING_RATE_GAMMA = 0.9\n",
    "LEARNING_RATE_STEP_SIZE = 2\n",
    "\n",
    "# Setup optimizer, loss and learning rate scheduler functions\n",
    "loss_func = tnn.CrossEntropyLoss()\n",
    "optimizer = toptim.Adam(model.parameters(), lr=BASE_LEARNING_RATE)\n",
    "lr_sched = toptim.lr_scheduler.StepLR(optimizer=optimizer, gamma=LEARNING_RATE_GAMMA, step_size=LEARNING_RATE_STEP_SIZE)\n",
    "\n",
    "# Track the loss during training and evaluation together\n",
    "training_losses = []\n",
    "evaluation_losses = []\n",
    "\n",
    "training_accuracy_values = []\n",
    "evaluation_accuracy_values = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"=\"*20)\n",
    "    print(f\"Epoch: {epoch + 1}/{EPOCHS}\")\n",
    "\n",
    "    # Ensure node dropout is active by switching to train mode\n",
    "    model.train()\n",
    "\n",
    "    train_correct_predictions = 0\n",
    "    train_total_predictions = 0\n",
    "    train_epoch_loss = 0.0\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        for img_batch, lbl_batch in training_set_loader:\n",
    "            # Send the data to the GPU VRAM if one is available\n",
    "            img_batch = img_batch.to(COMPUTE_DEVICE)\n",
    "            lbl_batch = lbl_batch.to(COMPUTE_DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            batch_outputs = model(img_batch)\n",
    "\n",
    "            batch_loss = loss_func(batch_outputs, lbl_batch)\n",
    "            train_epoch_loss += batch_loss.item()\n",
    "\n",
    "            prediction_confidence, predicted_classes = torch.max(batch_outputs, 1)\n",
    "\n",
    "            train_total_predictions += lbl_batch.size(0)\n",
    "            train_correct_predictions += (predicted_classes == lbl_batch).sum().item()\n",
    "\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        lr_sched.step()\n",
    "        print(f\"Train Model Accuracy: {100 * (train_correct_predictions/train_total_predictions):.2f}\")\n",
    "        print(f\"Train Loss: {train_epoch_loss/len(training_set_loader)}\")\n",
    "        print(f\"Learning Rate: {lr_sched.get_last_lr()}\")\n",
    "\n",
    "    # Ensure model is in evaluation mode to perform inference\n",
    "    # Full network available, no node dropout\n",
    "    model.eval()\n",
    "\n",
    "    eval_correct_predictions = 0\n",
    "    eval_total_predictions = 0\n",
    "    eval_epoch_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img_batch, lbl_batch in evaluation_set_loader:\n",
    "            img_batch = img_batch.to(COMPUTE_DEVICE)\n",
    "            lbl_batch = lbl_batch.to(COMPUTE_DEVICE)\n",
    "\n",
    "            batch_outputs = model(img_batch)\n",
    "\n",
    "            batch_loss = loss_func(batch_outputs, lbl_batch)\n",
    "            eval_epoch_loss += batch_loss.item()\n",
    "\n",
    "            prediction_confidence, predicted_classes = torch.max(batch_outputs.data, 1)\n",
    "\n",
    "            eval_total_predictions += lbl_batch.size(0)\n",
    "            eval_correct_predictions += (predicted_classes == lbl_batch).sum().item()\n",
    "\n",
    "    print(f\"Eval Model Accuracy: {100 * (eval_correct_predictions/eval_total_predictions):.2f}%\")\n",
    "    print(f\"Eval Loss: {eval_epoch_loss/len(evaluation_set_loader)}\")\n",
    "\n",
    "    training_losses.append((train_epoch_loss/len(training_set_loader)))\n",
    "    evaluation_losses.append((eval_epoch_loss/len(evaluation_set_loader)))\n",
    "\n",
    "    training_accuracy_values.append((train_correct_predictions/train_total_predictions))\n",
    "    evaluation_accuracy_values.append((eval_correct_predictions/eval_total_predictions))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c93a5b",
   "metadata": {},
   "source": [
    "## Testing and Evaluation\n",
    "\n",
    "A character recognition system can be evaluated with a simple performance measure wherein the number of correct classifications and misclassifications can be compared against the total classifications performed, this would provide a success rate and error rate which would be sufficient to pronounce the success of the model in solving the initial problem.\n",
    "\n",
    "$Error Rate = Incorrect Classifications / Total Classifications$\n",
    "\n",
    "For a computer vision task such as OCR, it is imperative that the end system generalize well upon the data that it's trained upon. That is to say, it should learn the common features of the various classes without accidentally 'memorizing' any one specific instance of that class. The phenomenon where the model _does_ memorize the features of any specific instances of training data is called 'Overfitting'. We can determine if a model is overfitting by comparing the loss function output during training and during evaluation using the different datasets, one which the model has 'seen' previously and one which it has not.\n",
    "\n",
    "The below code snippet generates some graphs that present these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3f8ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(training_losses, label='Training Loss', marker='o')\n",
    "plt.plot(evaluation_losses, label='Evaluation Loss', marker='o')\n",
    "plt.title('Training vs Evaluation Loss (Overfitting)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(training_accuracy_values, label='Training Accuracy', marker='o')\n",
    "plt.plot(evaluation_accuracy_values, label='Evaluation Accuracy', marker='o')\n",
    "plt.title('Training vs Evaluation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab5ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    img_batch, lbl_batch = next(iter(evaluation_set_loader))\n",
    "\n",
    "    img_batch = img_batch.to(COMPUTE_DEVICE)\n",
    "    lbl_batch = lbl_batch.to(COMPUTE_DEVICE)\n",
    "\n",
    "    batch_outputs = model(img_batch)\n",
    "    prediction_confidence, predicted_classes = torch.max(batch_outputs, 1)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    for i in range(25):\n",
    "        img = img_batch[i]\n",
    "        lbl = lbl_batch[i]\n",
    "        pred_class = predicted_classes[i]\n",
    "\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        plt.xlabel(f\"P: {label_character_map[pred_class]}, A: {label_character_map[lbl]}, {\"CORRECT\" if pred_class == lbl else \"WRONG\"}\")\n",
    "        plt.imshow(img.cpu().numpy().squeeze(), cmap='gray')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ba9f1d",
   "metadata": {},
   "source": [
    "As can be seen from the data above, the implemented model performs with very high accuracy and is able to classify data that has not been in the training set, this points to a robust generalization in the learning process. This makes it so that the model is capable of recognizing digits in a wide variety of scenarios. The implementation of the model and it's lightweight nature demonstrates the viability of using said model in low power, constrained systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450da151",
   "metadata": {},
   "source": [
    "## Equity, Diversity and Inclusion\n",
    "\n",
    "In terms of EDI, the primary concern would be around the dataset used to train any ML models. In this particular case the dataset could be perceived as limiting due to the fact that it is composed entirely of Arabic/Indian numerals. Cultures and languages that make use of differing digits such as China, Japan and the Middle East would not be able to be served by the model. Further expanding the dataset with additional types of numbers is one possibility as well as training separate models to specialize in those different scripts.\n",
    "\n",
    "In terms of environmental sustainability, the model slims down the traditional CNN architecture while still maintaining extremely high accuracy, in the context of modern consumer hardware the storage requirements of the dataset as well as the processing required for the training can be considered small to the point of irrelevance. The model can be comfortably run on older CPUs from a decade prior with minimal RAM requirements (128MB)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935d2d36",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Cireşan, D.C. et al. (2010). Deep, Big, Simple Neural Nets for Handwritten Digit Recognition. Neural Computation, 22 (12), 3207–3220. Available from https://doi.org/10.1162/NECO_a_00052.\n",
    "\n",
    "Dosovitskiy, A. et al. (2020). An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. Available from https://doi.org/10.48550/ARXIV.2010.11929 [Accessed 2 January 2026].\n",
    "\n",
    "El Ibrahimi, A. et al. (2025). Advancements in CNN Architectures for Offline Handwritten Arabic Character Recognition. E3S Web of Conferences, 601, 00015. Available from https://doi.org/10.1051/e3sconf/202560100015.\n",
    "\n",
    "Lecun, Y. et al. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86 (11), 2278–2324. Available from https://doi.org/10.1109/5.726791.\n",
    "\n",
    "Liu, C.-L. et al. (2003). Handwritten digit recognition: benchmarking of state-of-the-art techniques. Pattern Recognition, 36 (10), 2271–2285. Available from https://doi.org/10.1016/S0031-3203(03)00085-2.\n",
    "\n",
    "Liu, W., Wei, J. and Meng, Q. (2020). Comparisions on KNN, SVM, BP and the CNN for Handwritten Digit Recognition. 2020 IEEE International Conference on Advances in Electrical Engineering and Computer Applications( AEECA), 587–590. Available from https://doi.org/10.1109/AEECA49918.2020.9213482.\n",
    "\n",
    "Srivastava, N. et al. (2014). Dropout: A Simple Way to Prevent Neural Networks from Overfitting. Journal of Machine Learning Research, 15 (56), 1929–1958.\n",
    "\n",
    "Vaswani, A. et al. (2017). Attention Is All You Need. Available from https://doi.org/10.48550/ARXIV.1706.03762 [Accessed 2 January 2026].\n",
    "\n",
    "ylecun/mnist · Datasets at Hugging Face. (2024). Available from https://huggingface.co/datasets/ylecun/mnist [Accessed 2 January 2026].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aec48b",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "### Devcontainer definition for running the notebook\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"name\": \"Jupyter Dev Environment\",\n",
    "    \"image\": \"quay.io/jupyter/pytorch-notebook:cuda12-python-3.13.11\",\n",
    "    \"runArgs\": [\n",
    "        \"--gpus\",\n",
    "        \"all\"\n",
    "    ],\n",
    "    \"customizations\": {\n",
    "        \"vscode\": {\n",
    "            \"extensions\": [\n",
    "                \"ms-toolsai.jupyter\",\n",
    "                \"ms-python.python\"\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    // \"postStartCommand\": \"mamba install -f ./requirements.txt\"\n",
    "}\n",
    "```\n",
    "\n",
    "### Python requirements file for the notebook\n",
    "```\n",
    "torch\n",
    "torchvision\n",
    "matplotlib-base\n",
    "matplotlib-inline\n",
    "pillow\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
